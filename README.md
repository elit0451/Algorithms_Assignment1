# Base Algorithms for sorting ğ’®â„‹ğ’œğ’¦â„°ğ’®ğ’«â„°ğ’œâ„›â„°  's work 

The following solution provides implementation for 3 Base algorithms, which sort Shakespeare's work from a text file.

## Features
- Read Shakespeare's work from a text file. ğŸ“–
  - Process the text to **lower case** and **without any punctuation**.
- Algorithms used: ğŸ§®
  - Insertion Sort
  - Selection Sort
  - Merge Sort
- Outputting the time consumption â± for each algorithm and an alphabetically sorted word array 

### Starting the program â–¶ï¸
- Clone the project through `git clone https://github.com/davi7725/Algorithms_Assignment1.git` or just download it as a ZIP file
- Open the project into an IDE that supports   <img src="./java.png" height="50">    applications
- Change file path in [Main.java](https://github.com/davi7725/Algorithms_Assignment1/blob/9fdd4a3a62e0165d0f6c28384cf797044385c813/src/main/java/com/cphbusiness/basicalgorithms/Main.java#L31) to the path of your [dataset](https://raw.githubusercontent.com/datsoftlyngby/soft2019spring-algorithms/master/Weeklies/Week_05/Assignment_01/Shakespeare_Complete_Works.txt)
- Start the application by running the *Main* file

_NBâ—ï¸ you can download the Shakespeare's works from the hyperlink attached to the word **dataset**_

_âš ï¸ Be aware that it will take some time to load the full dataset, therefore coffee â˜•ï¸ or tea ğŸµ break is advisable_

___
| Algorithm  | Complexity  | Results /microseconds/ |
| :------------ |:---------------:| -----:|
| Insertion sort      | Best case - O(N) <br/> **Average case - O(N^2)** <br/> Worst case - O(N^2) |  500ln - 74 065 Î¼s <br/> 1000ln - 352 803 Î¼s|
| Selection sort      | Best case - O(N^2) <br/> **Average case - O(N^2)** <br/> Worst case - O(N^2)        | 500ln - 101 116 Î¼s <br/> 1000ln - 221 485 Î¼s |
| Merge sort | Best case - O(N logN) <br/> **Average case - O(N logN)** <br/> Worst case - O(N logN)        | 500ln - 10 284  Î¼s <br/> 1000ln - 12 065 Î¼s   |


From the results demonstrated can be concluded that **Merge sort** would the most favourable for sorting large amounts of data. Supporting this decision is the argument that duplicating the dataset, doesn't result on prolonging the time twice as long.  
___
> #### Assignment made by:   
`David Alves ğŸ‘¨ğŸ»â€ğŸ’» ` :octocat: [Github](https://github.com/davi7725) <br />
`Elitsa Marinovska ğŸ‘©ğŸ»â€ğŸ’» ` :octocat: [Github](https://github.com/elit0451) <br />
> Attending "Algorithms and Data Structures" course of Software Development bachelor's degree
